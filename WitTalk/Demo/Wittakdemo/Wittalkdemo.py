from openai import OpenAI
import streamlit as st
import time
import json 
from TTS.tts import voice_generator
import librosa
import whisper
from tempfile import NamedTemporaryFile
from utils import DataPipeline , get_emotion_using_triton

 

JSON_PATH = "./asset/wittalkdemo.json"
USER = "ë³„ì´"
DOG_EMO = None
ASSISTANT_ID = "asst_4AcrN8f4LuWzP5DyR8cRdaTG"

with open(JSON_PATH , 'r' , encoding='utf-8') as f:
    json_data = json.load(f)

pipleline = DataPipeline()


# ë°˜ë ¤ê²¬ì˜ ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , í•´ë‹¹ ìŒì„±ì— ë§ëŠ” ê°ì • ìƒíƒœë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 
# ê°ì •ì¶”ì¶œì˜ ê²°ê³¼ëŠ” ì¢Œì¸¡ í•˜ë‹¨ì— ì²´í¬ë°•ìŠ¤ì— í‘œê¸°ë©ë‹ˆë‹¤.
# ê°ì •ì¶”ì¶œì€ Bark2text ëª¨ë¸ì´ triton ì„œë²„ì—ì„œ ì¶”ë¡ í•˜ê²Œë©ë‹ˆë‹¤. ë”°ë¼ì„œ triton ì„œë²„ê°€ ë™ì‘í•˜ê³  ìˆì–´ì•¼í•©ë‹ˆë‹¤.
upload_dogsound = st.file_uploader("Upload an dog audio(.wav) file", type=["wav"])
if upload_dogsound is not None:
    with NamedTemporaryFile(suffix=".wav") as temp:
        temp.write(upload_dogsound.getvalue())
        temp.seek(0)
        temp_dogsound  ,sr = librosa.load(temp  ,sr = 16000)
        #st.audio(temp_dogsound , sample_rate = 16000)
        input_data= pipleline.execute(temp_dogsound , sr)
        DOG_EMO = get_emotion_using_triton(input_data)


with st.sidebar:

    
    openai_api_key = st.text_input("OpenAI API Key", key="chatbot password", type="password")
    client = OpenAI(api_key=openai_api_key)
    thread_id = json_data[USER]['thread_key']


    action = st.text_input("ë°˜ë ¤ê²¬ì˜ í˜„ì¬ ìƒí™©" , key = "action")

    sample_sound , sr= librosa.load('./TTS/resources/example_reference2.mp3' , sr = 44100)
    st.audio(sample_sound ,format = "audio/mp3" , sample_rate = 44100)

    st.caption("ìœ„ ì˜¤ë””ì˜¤ëŠ” ì‚¬ìš©ì ëª©ì†Œë¦¬ ìƒ˜í”Œì…ë‹ˆë‹¤.")


    # check boxë¥¼ í†µí•´ ë°˜ë ¤ê²¬ì˜ í˜„ì¬ ê°ì •ì„ ë³´ì—¬ì¤Œ 
    st.write('ë°˜ë ¤ê²¬ í˜„ì¬ ê°ì •')
    
    if DOG_EMO == 'bark':
        happy = st.checkbox('í–‰ë³µí•´' , value = True , disabled = True)
    else:
        happy = st.checkbox('í–‰ë³µí•´' , value = False , disabled = True)

    if DOG_EMO == 'whining':
        sad = st.checkbox('ìŠ¬í¼' , value = True, disabled = True)
    else:
        sad = st.checkbox('ìŠ¬í¼' , value = False, disabled = True)

    if DOG_EMO == 'growling':
        angry = st.checkbox('í™”ë‚œë‹¤' , value = True, disabled = True)
    else:
        angry = st.checkbox('í™”ë‚œë‹¤' , value = False, disabled = True)

    if DOG_EMO == 'howling':
        fear = st.checkbox('ë‘ë µë‹¤' , value = True, disabled = True)
    else:
        fear = st.checkbox('ë‘ë µë‹¤ ' , value = False, disabled = True)

    if happy == True:
        emotion = "í–‰ë³µí•¨"
    elif angry == True:
        emotion = "í™”ë‚¨"
    elif sad == True:
        emotion = "ìŠ¬í””"
    elif fear == True:
        emotion = "ë‘ë µë‹¤"
        



st.title("ğŸ¶ WitTalk Demo")
st.subheader(f"í˜„ì¬ ìœ—í†¡ì€ {USER}ì™€ ëŒ€í™”ì¤‘ì´ì—ìš”",divider=True)

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": f"ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” {USER}ì—ìš”. ë©!"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    #í…ìŠ¤íŠ¸ì—ì„œ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë¶€ë¶„
    # í•˜ë‚˜ëŠ” Openaiì—ì„œ ì œê³µí•˜ëŠ” ê¸°ë³¸ tts , ê·¸ë¦¬ê³  ë‚˜ì˜ ëª©ì†Œë¦¬ë¥¼ ì…íŒ ttsë‘ê°€ì§€ ë²„ì „ì„ ì œê³µí•œë‹¤.
    tts_speaker , my_spearker = voice_generator(prompt)
    #tts_sound  , sr = librosa.load(tts_speaker , sr = 44100)
    my_sound  , sr= librosa.load(my_spearker , sr = 44100)

    st.write("ì‚¬ìš©ìì˜ ì±„íŒ…ì— ëŒ€í•´ ì‚¬ìš©ì ìŒì„±ì…íŒ TTSë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
    #st.audio(tts_sound , format = "audio/wav" , sample_rate= 44100)
    st.audio(my_sound , format = "audio/wav" , sample_rate= 44100)

    # inference server ì—ì„œ ê°ì •ê°’ emotion
    # actionì€ ì¹´ë©”ë¼ì—ì„œ ë°›ì•„ì™€ì•¼í•¨ motion captureí•´ì„œ ê°•ì•„ì§€ê°€ ìˆëŠ”ì§€ ì—†ëŠ”ì§€

    text_form = f"""
                    ìƒí™© : {action}      
                    ê°ì •ìƒíƒœ : {emotion}
                    ì±„íŒ… : {prompt}
                    
                """
    print(text_form)    
    
    response = client.beta.threads.messages.create(
        thread_id,
        role="user",
        content= text_form
    )

    run = client.beta.threads.runs.create(
    thread_id=thread_id,
    assistant_id=ASSISTANT_ID
    )

    run_id = run.id

    while True:

        run = client.beta.threads.runs.retrieve(
        thread_id = thread_id,
        run_id = run_id
        )

        if run.status =='completed':
            break
        else : time.sleep(2)

    thread_messages = client.beta.threads.messages.list(thread_id)

    msg = thread_messages.data[0].content[0].text.value
    st.session_state.messages.append({"role" : "assistant" , "content" : msg})
    st.chat_message("assistant").write(msg)

